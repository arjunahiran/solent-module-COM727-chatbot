{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjunahiran/solent-module-COM727-chatbot/blob/main/Copy_of_LungCancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl-2pCHpEFyT"
      },
      "source": [
        "# ***Import Necessary Libraries***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dP0y4GugJGmd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import PIL\n",
        "from google.colab import files\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "#from tensorflow.keras.utils import image_dataset_from_directory, img_to_array\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv2D, AvgPool2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "#from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YocyQzUMEEth"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pFP2MsjVmwD"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbomQqaXJZhy"
      },
      "outputs": [],
      "source": [
        "image = PIL.Image.open(\"/content/gdrive/MyDrive/COM726/test/adenocarcinoma/000177.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlsPuIrbT1Jh"
      },
      "outputs": [],
      "source": [
        "#gpu_info = !nvidia-smi\n",
        "#gpu_info = '\\n'.join(gpu_info)\n",
        "#if gpu_info.find('failed') >= 0:\n",
        "  #print('Not connected to a GPU')\n",
        "#else:\n",
        "  #print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbVeSFVLWFFe"
      },
      "outputs": [],
      "source": [
        "image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ko2PRAOlaDCq"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "learning_rate = 0.0001\n",
        "input_size = (224,224)\n",
        "batch_size=32\n",
        "monitor=\"val_loss\"\n",
        "list_model = [\"ResNet101\", \"ResNet152\", \"VGG16\", \"EfficientNetB6\", \"EfficientNetB7\"]\n",
        "list_model_acc = []\n",
        "list_model_loss = []\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfON0SVke9x4"
      },
      "outputs": [],
      "source": [
        "def plot_loss_acc(history) :\n",
        "    \"\"\"\n",
        "    Plots line plots of model accuracy and model loss.\n",
        "\n",
        "    Args:\n",
        "        history (object): The history of the model.\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
        "    ax[0].plot(history.history['accuracy'])\n",
        "    ax[0].plot(history.history['val_accuracy'])\n",
        "    ax[0].set_title('Model Accuracy')\n",
        "    ax[0].set_xlabel('Epochs')\n",
        "    ax[0].set_ylabel('Accuracy')\n",
        "    ax[0].legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "    ax[1].plot(history.history['loss'])\n",
        "    ax[1].plot(history.history['val_loss'])\n",
        "    ax[1].set_title('Model Loss')\n",
        "    ax[1].set_xlabel('Epochs')\n",
        "    ax[1].set_ylabel('Loss')\n",
        "    ax[1].legend(['train', 'val'], loc='upper left')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AebQnoFofLqd"
      },
      "outputs": [],
      "source": [
        "def eval_test(model,checkPoint_path):\n",
        "    \"\"\"\n",
        "    Prints classification report and plots confusion matrix heatmap on the test data\n",
        "    Stores accuracy and loss of models\n",
        "\n",
        "    Args:\n",
        "        model (object) : The model to be evaluated.\n",
        "        checkPoint_path (str) : The path of the checkpoint\n",
        "    \"\"\"\n",
        "    model.load_weights(checkPoint_path)\n",
        "    test_evaluate = model.evaluate(test_data)\n",
        "    list_model_acc.append(test_evaluate[1])\n",
        "    list_model_loss.append(test_evaluate[0])\n",
        "    y_pred = model.predict(test_data)\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "    print(classification_report(y_pred,test_data.classes))\n",
        "    cm = confusion_matrix(y_pred,test_data.classes)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    ax = disp.plot(cmap='Blues').ax_\n",
        "    ax.set_title(\"Confusion matrix in test data\")\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAm1YYUFgDjt"
      },
      "source": [
        "**LOAD DATA FROM DIRECTORY**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kltAfl5YpH_d"
      },
      "source": [
        "**EDA/PreProcessing on Lung cancer images**\n",
        "\n",
        ">\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gm_tE6VwobH6"
      },
      "outputs": [],
      "source": [
        "#To check and remove when junk folder ipynb is created\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "folder_path = '/content/gdrive/MyDrive/COM726/train/.ipynb_checkpoints'\n",
        "\n",
        "if os.path.exists(folder_path):\n",
        "    shutil.rmtree(folder_path)\n",
        "    print(\"Folder deleted successfully.\")\n",
        "else:\n",
        "    print(\"Folder not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PRSI_bHZ0No"
      },
      "outputs": [],
      "source": [
        "ROOT_DIR=\"/content/gdrive/MyDrive/COM726\"\n",
        "number_of_images = {}\n",
        "\n",
        "\n",
        "# Iterate over the train, valid, and test directories\n",
        "for subset in [\"train\", \"valid\", \"test\"]:\n",
        "    subset_dir = os.path.join(ROOT_DIR, subset)\n",
        "    number_of_images[subset] = {}\n",
        "\n",
        "    # Iterate over each class directory within the subset directory\n",
        "    for class_dir in os.listdir(subset_dir):\n",
        "        class_path = os.path.join(subset_dir, class_dir)\n",
        "        if os.path.isdir(class_path):  # Check if it's a directory\n",
        "            number_of_images[subset][class_dir] = len(os.listdir(class_path))\n",
        "\n",
        "# Print the counts\n",
        "for subset, classes in number_of_images.items():\n",
        "    print(f\"{subset.capitalize()} data:\")\n",
        "    for class_name, count in classes.items():\n",
        "        print(f\"  {class_name}: {count} images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GqhILu_X3ro"
      },
      "source": [
        "**Pre processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1Ue7Ymb_dD6"
      },
      "outputs": [],
      "source": [
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Verify the mount\n",
        "!ls /content/drive/MyDrive/COM726/train\n",
        "\n",
        "# Step 3: Define the preprocessing function\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wa7VoFL5-PC6"
      },
      "outputs": [],
      "source": [
        "def preprocessingImages1(path):\n",
        "    \"\"\"\n",
        "    Input: path\n",
        "    Output: preprocessed images\n",
        "    \"\"\"\n",
        "    image_data = ImageDataGenerator(zoom_range=0.2, shear_range=0.2, rescale=1/255, horizontal_flip=True, fill_mode='nearest')\n",
        "    #image_data = ImageDataGenerator(vertical_flip=True,zoom_range=0.1,width_shift_range=0.1,\n",
        "    #height_shift_range=0.1,\n",
        "    #rotation_range=10,\n",
        "    #horizontal_flip=True,\n",
        "    #fill_mode='nearest', rescale=1/255)\n",
        "\n",
        "\n",
        "    image = image_data.flow_from_directory(directory=path, target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
        "    return image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niE3BEmdEd71"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/COM726/train\"\n",
        "train_data = preprocessingImages1(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUHqKSKzFrah"
      },
      "outputs": [],
      "source": [
        "def preprocessingImages2(path):\n",
        "    \"\"\"\n",
        "    Input: path\n",
        "    Output: preprocessed images\n",
        "    \"\"\"\n",
        "    image_data = ImageDataGenerator(rescale=1/255)\n",
        "    image = image_data.flow_from_directory(directory=path, target_size=(224, 224), shuffle=True, batch_size=32, class_mode='categorical')\n",
        "    return image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoPqlrEEGAcX"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/COM726/test\"\n",
        "test_data = preprocessingImages2(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPyGNlF8GhOY",
        "outputId": "fd679744-d1ff-432a-9898-c8c78c63293b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 72 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "path = \"/content/drive/MyDrive/COM726/valid\"\n",
        "valid_data = preprocessingImages2(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R50OdgoUJBqa"
      },
      "outputs": [],
      "source": [
        "class_names = list(test_data.class_indices.keys())\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for i, (images, labels) in enumerate(train_data):\n",
        "    if i == 15:\n",
        "        break\n",
        "    plt.subplots_adjust(hspace=0.5)\n",
        "    plt.subplot(3, 5, i + 1)\n",
        "    # Convert the image to uint8 and scale if necessary\n",
        "    img = images[0]\n",
        "    if img.max() <= 1.0:  # Check if the image is normalized between 0 and 1\n",
        "        img = (img * 255).astype(\"uint8\")\n",
        "    else:\n",
        "        img = img.astype(\"uint8\")\n",
        "    plt.imshow(img)\n",
        "    class_index = np.argmax(labels[0])  # Use np.argmax to find the index of the class\n",
        "    class_name = class_names[class_index]\n",
        "    plt.title(class_name)\n",
        "    plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSmnk7khYHoA"
      },
      "source": [
        "**MODEL BUILD**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "uKmvbO1mYGlY"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Conv2D, AvgPool2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAvgPool2D, GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.applications import VGG16, EfficientNetB5\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import keras\n",
        "from tensorflow.keras.optimizers import Adam, Adamax\n",
        "from tensorflow.keras import regularizers\n",
        "#from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.applications import vgg16\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSwL8pr8Xl96"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxSVCKbhYQJg"
      },
      "source": [
        "**#1 VGG16**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "kH2sqUahkURv"
      },
      "outputs": [],
      "source": [
        "vgg16=VGG16(weights='imagenet', input_shape=(224,224,3), classes=4, include_top=False)\n",
        "\n",
        "for layer in vgg16.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "#for layer in vgg16.layers[-4:]:  # Unfreeze the last 4 layers, for example\n",
        "    #layer.trainable = True\n",
        "\n",
        "x= Flatten()(vgg16.output)\n",
        "x = Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "x= Dropout(0.5)(x)\n",
        "predictions = Dense(4, activation='softmax')(x)\n",
        "model=Model(inputs=vgg16.input, outputs=predictions)\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "sB2mIZUtYMSJ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "AQVP6yEEnNFE"
      },
      "outputs": [],
      "source": [
        "#Early stopping and model check point\n",
        "es = EarlyStopping(monitor='val_accuracy', min_delta=0.01,patience=15, verbose=1, mode=\"auto\")\n",
        "\n",
        "mc = ModelCheckpoint(monitor='val_accuracy', filepath='/content/drive/MyDrive/COM726/bestmodel.keras', save_best_only=True)\n",
        "\n",
        "#es = EarlyStopping(monitor='accuracy', patience=10, restore_best_weights=True)\n",
        "#mc = ModelCheckpoint('/content/drive/MyDrive/COM726/bestmodel.keras', monitor='accuracy',\n",
        "cd= [es,mc]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "id": "38YgOC3snVj5",
        "outputId": "6667097e-f1db-4d15-ee91-6baccc8bcc81"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block1_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m1,792\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block1_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m36,928\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block1_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block2_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block2_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m147,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block2_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block3_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m295,168\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block3_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m590,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block3_conv3 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m590,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block3_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block4_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m1,180,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block4_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block4_conv3 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block4_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block5_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block5_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block5_conv3 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block5_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │       \u001b[38;5;34m6,422,784\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │           \u001b[38;5;34m1,028\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block1_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block1_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block1_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block2_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block2_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block2_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block3_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block3_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block3_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block3_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block4_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block4_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block4_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block4_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block5_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block5_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block5_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block5_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">6,422,784</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,028</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,138,500\u001b[0m (80.64 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,138,500</span> (80.64 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,423,812\u001b[0m (24.50 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,423,812</span> (24.50 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#model=vgg16.model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "collapsed": true,
        "id": "cOscVb3VmigT",
        "outputId": "65dbd55e-901c-401c-fe8d-45fd93a95e92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 458ms/step - accuracy: 0.8642 - loss: 0.5656 - val_accuracy: 0.8333 - val_loss: 0.7429\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'items'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-de46a41804e1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#history = model.fit(train_data, steps_per_epoch=len(train_data), validation_data=valid_data, epochs=10, validation_steps=5,   callbacks=cd)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#history = model.fit(train_data, steps_per_epoch=len(train_data), validation_data=valid_data, epochs=10, validation_steps=5, callbacks=cd)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    352\u001b[0m                 )\n\u001b[1;32m    353\u001b[0m                 val_logs = {\n\u001b[0;32m--> 354\u001b[0;31m                     \u001b[0;34m\"val_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m                 }\n\u001b[1;32m    356\u001b[0m                 \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
          ]
        }
      ],
      "source": [
        "hs = model.fit(train_data, steps_per_epoch=len(train_data), epochs=30, validation_data=valid_data, validation_steps=3)\n",
        "#history = model.fit(train_data, steps_per_epoch=len(train_data), validation_data=valid_data, epochs=10, validation_steps=5,   callbacks=cd)\n",
        "#history = model.fit(train_data, steps_per_epoch=len(train_data), validation_data=valid_data, epochs=10, validation_steps=5, callbacks=cd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOPaZXyRFGsy"
      },
      "outputs": [],
      "source": [
        "# Checking Accuracy using VGG16 Model\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "# Plotting Training and Validation Accuracy\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy', color='r')\n",
        "plt.plot(val_acc, label='Validation Accuracy', color='b')\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.legend(loc='lower right', fontsize=13)\n",
        "plt.ylabel('Accuracy', fontsize=16, weight='bold')\n",
        "plt.title('Training & Validation Accuracy for VGG16', fontsize=16, weight='bold')\n",
        "\n",
        "# Plotting Training and Validation Loss\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss', color='r')\n",
        "plt.plot(val_loss, label='Validation Loss', color='b')\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.legend(loc='upper right', fontsize=13)\n",
        "plt.ylabel('Cross Entropy', fontsize=16, weight='bold')\n",
        "plt.title('Training & Validation Loss for VGG16', fontsize=15, weight='bold')\n",
        "plt.xlabel('Epoch', fontsize=15, weight='bold')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EO_LvEBLACJe"
      },
      "outputs": [],
      "source": [
        "# Saved the model after setting these parameters vertical_flip=True, width_shift_range=0.2, height_shift_range=0.2(VGG16_lung_cancer)\n",
        "model.save(\"/content/drive/MyDrive/COM726/vgg16_withFreezelayers.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_loss, test_acc = model.evaluate(valid_data)\n",
        "print(f\"Test Accuracy: {test_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPA2G1unIH0g"
      },
      "outputs": [],
      "source": [
        "#Early stopping and model check point\n",
        "es = EarlyStopping(monitor=\"accuracy\", min_delta=0.01,\n",
        "    patience=15, verbose=1, mode=\"auto\")\n",
        "\n",
        "mc = ModelCheckpoint(monitor=\"accuracy\", filepath=\"./bestmodel.h5\", verbose=1, save_best_only=True, mode='auto')\n",
        "\n",
        "cd= [es,mc]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQBWg_fhL4D_"
      },
      "source": [
        "MODEL TRAINING\n",
        "#VGG16 Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weLBUjhgKnkG"
      },
      "outputs": [],
      "source": [
        "#Model Training\n",
        "\"\"\"\n",
        "hs = model.fit_generator(generator=train_data,\n",
        "                         steps_per_epoch =8,\n",
        "                         epochs=30,\n",
        "                         verbose=1, validation_data=valid_data,\n",
        "                         validation_steps =16,\n",
        "                         callbacks=cd)\n",
        "                         \"\"\"\n",
        "\n",
        "##hs = model.fit(train_data, epochs=30, verbose=1, validation_data=valid_data, validation_steps=16, callbacks=cd)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_GEempyXUHs"
      },
      "source": [
        "Achieved a Training Accuracy of 95% and Validation Acc of 81% with VGG16, now lets move to InceptionResNetV2 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNh_CZWDZnMJ"
      },
      "outputs": [],
      "source": [
        "classes=list(train_data.class_indices.keys())\n",
        "class_count=len(classes)\n",
        "\n",
        "print(class_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuSp25R8bvzi"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model, load_model, Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.metrics import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.optimizers import *\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik-2sUokYLPb"
      },
      "source": [
        "**#2 InceptionResNetV2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSPg03SOYRMD"
      },
      "outputs": [],
      "source": [
        "model_name='InceptionResNetV2'\n",
        "base_model=tf.keras.applications.InceptionResNetV2(include_top=False, weights=\"imagenet\",input_shape=(224, 224, 3), pooling='max')\n",
        "x=base_model.output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNMHGgFzjCdJ"
      },
      "outputs": [],
      "source": [
        "#Early stopping and model check point for InceptionResnetV2 model\n",
        "es = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1)\n",
        "\n",
        "mc = ModelCheckpoint(monitor=\"val_loss\", filepath=\"./bestmodel.h5\", verbose=1, save_best_only=True, mode='auto')\n",
        "\n",
        "cd= [es,mc]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1jMaXvkYV_l"
      },
      "outputs": [],
      "source": [
        "# Add new layers\n",
        "x = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)\n",
        "\n",
        "x = Dense(256, kernel_regularizer=regularizers.l2(0.02), activity_regularizer=regularizers.l1(0.01),\n",
        "          bias_regularizer=regularizers.l1(0.01), activation='relu')(x)\n",
        "#x = Dense(256, kernel_regularizer = regularizers.l2(0.016),activity_regularizer=regularizers.l1(0.006),\n",
        "                #bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n",
        "x = Dropout(rate=0.45, seed=123)(x)\n",
        "output = Dense(4, activation='softmax')(x)\n",
        "model=Model(inputs=base_model.input, outputs=output)\n",
        "model.compile(Adamax(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  #Precision(name='precision'),**/\n",
        "                     # Recall(name='recall'),**/\n",
        "                      #AUC(name='auc'),**/\n",
        "                     #RootMeanSquaredError(name='root_mean_squared_error')])**/\n",
        "#model.compile(Adamax(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5VNN49UYf7x"
      },
      "outputs": [],
      "source": [
        "#early_stopping=EarlyStopping(monitor='val_loss', patience=3)\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=valid_data,\n",
        "    epochs=30,\n",
        "    callbacks=cd)\n",
        "#model.save_weights(\"model.h5\")\n",
        "model.save(\"InceptionResNetV2.hd5\")\n",
        "print(\"Saved model to disk\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEL2N2Rin1e_"
      },
      "source": [
        "**InceptionResnet Model achived 83% of training accuracy however high loss %**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62uOHDPCdW9U"
      },
      "outputs": [],
      "source": [
        "#Checking Accuracy using InceptionResnet Model\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.subplot(2, 1, 1)\n",
        "\n",
        "plt.plot(acc, label='Training Accuracy', color='r')\n",
        "plt.plot(val_acc, label='Validation Accuracy', color='b')\n",
        "\n",
        "\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.legend(loc='lower right', fontsize=13)\n",
        "plt.ylabel('Accuracy', fontsize=16, weight='bold')\n",
        "plt.title('Training & Validation Acc.', fontsize=16, weight='bold')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss', color='r')\n",
        "plt.plot(val_loss, label='Validation Loss', color='b')\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.legend(loc='upper right', fontsize=13)\n",
        "plt.ylabel('Cross Entropy', fontsize=16, weight='bold')\n",
        "plt.title('Training & Validation Loss', fontsize=15, weight='bold')\n",
        "plt.xlabel('Epoch', fontsize=15, weight='bold')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ya8w8iSYqWK"
      },
      "source": [
        "**#3 EfficientNetB5 Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDJuLbnAY83r"
      },
      "outputs": [],
      "source": [
        "#Model Creation of EfficientNetB5\n",
        "# Using the EfficientNetB5 pre-trained model as a base model (without the fully connected layers)\n",
        "base_model = tf.keras.applications.efficientnet.EfficientNetB5(\n",
        "    include_top=False,     # Exclude the fully connected layers\n",
        "    weights=\"imagenet\",    # Load pre-trained ImageNet weights\n",
        "    input_shape=(224, 224, 3),  # Specify the input shape for the model\n",
        "    pooling='max'           # Use global max pooling as the final pooling layer\n",
        ")\n",
        "\n",
        "# Constructing the complete model using Sequential API\n",
        "model = Sequential([\n",
        "    base_model,  # EfficientNetB5 as the base model\n",
        "    BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001),  # Batch normalization layer\n",
        "    Dense(256,\n",
        "          kernel_regularizer=regularizers.l2(l=0.016),\n",
        "          activity_regularizer=regularizers.l1(0.006),\n",
        "          bias_regularizer=regularizers.l1(0.006),\n",
        "          activation='relu'),  # Dense layer with regularization and ReLU activation\n",
        "    Dropout(rate=0.45, seed=123),  # Dropout layer for regularization\n",
        "    Dense(4, activation='softmax')  # Output layer with softmax activation for multi-class classification\n",
        "])\n",
        "\n",
        "# Compile the model with specified optimizer, loss function, and evaluation metric\n",
        "model.compile(\n",
        "    optimizer=Adamax(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgt9AGbxkPil"
      },
      "outputs": [],
      "source": [
        "# Display a summary of the model architecture\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzqdmjmbkkHW"
      },
      "outputs": [],
      "source": [
        "# Retrieve the configuration of the optimizer used in the EfficientNetB5 base model\n",
        "model.optimizer.get_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ofQJkLhkwaw"
      },
      "outputs": [],
      "source": [
        "es = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
        "mc = ModelCheckpoint('model_weights_efficient_B5_2.h5',\n",
        "                             monitor='val_loss',\n",
        "                             save_best_only=True,\n",
        "                             save_weights_only=True,\n",
        "                             mode='min',\n",
        "                             verbose=1)\n",
        "\n",
        "cd= [es,mc]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNT-FqRzgv8B"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x= train_data,\n",
        "                    steps_per_epoch = 20,\n",
        "                    epochs= 30,\n",
        "                    callbacks=[cd],\n",
        "                    validation_data = valid_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOAQq6J7nw05"
      },
      "source": [
        "# Check for Missing or Corrupted Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8a6DPzP4lEiW"
      },
      "outputs": [],
      "source": [
        "#Check for Missing or Corrupted Files\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def check_for_corrupted_images(directory):\n",
        "    corrupted_files = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith(('jpg', 'jpeg', 'png', 'bmp', 'tiff')):\n",
        "                file_path = os.path.join(root, file)\n",
        "                try:\n",
        "                    img = Image.open(file_path)\n",
        "                    img.verify()  # Verify that it is an image\n",
        "                except (IOError, SyntaxError) as e:\n",
        "                    print(f\"Corrupted file found: {file_path}\")\n",
        "                    corrupted_files.append(file_path)\n",
        "    return corrupted_files\n",
        "\n",
        "train_data = '/content/gdrive/MyDrive/COM726/train'\n",
        "valid_data = '/content/gdrive/MyDrive/COM726/valid'\n",
        "test_data = '/content/gdrive/MyDrive/COM726/test'\n",
        "\n",
        "corrupted_train = check_for_corrupted_images(train_data)\n",
        "corrupted_valid = check_for_corrupted_images(valid_data)\n",
        "corrupted_test = check_for_corrupted_images(test_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAjInpYEh4hG"
      },
      "source": [
        "**Check Image Quality**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WX_VZCGMLCYP"
      },
      "outputs": [],
      "source": [
        "def is_low_contrast_color(image, threshold=0.05):\n",
        "    # Apply is_low_contrast to each channel separately\n",
        "    for i in range(image.shape[-1]):  # Assuming image is in (height, width, channels) format\n",
        "        if exposure.is_low_contrast(image[..., i], fraction_threshold=threshold):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def check_image_quality(generator, num_batches=1):\n",
        "    low_quality_images = []\n",
        "    for _ in range(num_batches):\n",
        "        #images, _ = next(generator)\n",
        "        for img in images:\n",
        "            img = np.array(img).astype(np.uint8)\n",
        "            if img.ndim == 3:  # Check if image has color channels\n",
        "                if is_low_contrast_color(img):\n",
        "                    low_quality_images.append(img)\n",
        "            else:\n",
        "                if exposure.is_low_contrast(img):\n",
        "                    low_quality_images.append(img)\n",
        "    return low_quality_images\n",
        "\n",
        "# Assuming train_data, valid_data, and test_data are defined and are generators\n",
        "\n",
        "# Check low quality images\n",
        "low_quality_train = check_image_quality(train_data)\n",
        "low_quality_valid = check_image_quality(valid_data)\n",
        "low_quality_test = check_image_quality(test_data)\n",
        "\n",
        "print(f\"Low quality images in training set: {len(low_quality_train)}\")\n",
        "print(f\"Low quality images in validation set: {len(low_quality_valid)}\")\n",
        "print(f\"Low quality images in test set: {len(low_quality_test)}\")\n",
        "\n",
        "# Visualize low quality images if any\n",
        "def visualize_low_quality_images(images, title):\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    num_images = len(images)\n",
        "    for i in range(min(num_images, 5)):\n",
        "        plt.subplot(1, 5, i + 1)\n",
        "        plt.imshow(images[i])\n",
        "        plt.title(title)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_low_quality_images(low_quality_train, 'Low Quality - Train')\n",
        "visualize_low_quality_images(low_quality_valid, 'Low Quality - Valid')\n",
        "visualize_low_quality_images(low_quality_test, 'Low Quality - Test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eunO_-GwQlfN"
      },
      "outputs": [],
      "source": [
        "# Displaying the model performance\n",
        "def model_performance(history, Epochs):\n",
        "    # Define needed variables\n",
        "    tr_acc = history.history['accuracy']\n",
        "    tr_loss = history.history['loss']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    Epochs = [i+1 for i in range(len(tr_acc))]\n",
        "\n",
        "    # Plot training history\n",
        "    plt.figure(figsize= (20, 8))\n",
        "    plt.style.use('fivethirtyeight')\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
        "    plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
        "    plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "def model_evaluation(model):\n",
        "    train_score = model.evaluate(train_gen, verbose= 1)\n",
        "    valid_score = model.evaluate(valid_gen, verbose= 1)\n",
        "    test_score = model.evaluate(test_gen, verbose= 1)\n",
        "\n",
        "    print(\"Train Loss: \", train_score[0])\n",
        "    print(\"Train Accuracy: \", train_score[1])\n",
        "    print('-' * 20)\n",
        "    print(\"Validation Loss: \", valid_score[0])\n",
        "    print(\"Validation Accuracy: \", valid_score[1])\n",
        "    print('-' * 20)\n",
        "    print(\"Test Loss: \", test_score[0])\n",
        "    print(\"Test Accuracy: \", test_score[1])\n",
        "\n",
        "\n",
        "# Get Predictions\n",
        "def get_pred(model, test_gen):\n",
        "\n",
        "    preds = model.predict(test_gen)\n",
        "    y_pred = np.argmax(preds, axis = 1)\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "# Confusion Matrix\n",
        "def plot_confusion_matrix(test_gen, y_pred):\n",
        "\n",
        "    g_dict = test_gen.class_indices\n",
        "    classes = list(g_dict.keys())\n",
        "\n",
        "    # Display the confusion matrix\n",
        "    cm = confusion_matrix(test_gen.classes, y_pred)\n",
        "\n",
        "    plt.figure(figsize= (10, 10))\n",
        "    plt.imshow(cm, interpolation= 'nearest', cmap= plt.cm.Blues)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.colorbar()\n",
        "\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation= 45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Defining a convolutional NN block for a sequential CNN model\n",
        "def conv_block(filters, act='relu'):\n",
        "\n",
        "    block = Sequential()\n",
        "    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n",
        "    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n",
        "    block.add(BatchNormalization())\n",
        "    block.add(MaxPooling2D())\n",
        "\n",
        "    return block\n",
        "\n",
        "\n",
        "# Defining a dense NN block for a sequential CNN model\n",
        "def dense_block(units, dropout_rate, act='relu'):\n",
        "\n",
        "    block = Sequential()\n",
        "    block.add(Dense(units, activation=act))\n",
        "    block.add(BatchNormalization())\n",
        "    block.add(Dropout(dropout_rate))\n",
        "\n",
        "    return block"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1VbCIm0oGWA5HM1X_TE7IhEKlWo_pJbMD",
      "authorship_tag": "ABX9TyOpU/YR/WoNPPWe1Ekc0J5l",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}